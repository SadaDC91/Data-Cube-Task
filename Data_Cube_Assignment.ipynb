{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Data-Cube-Task**"
      ],
      "metadata": {
        "id": "4689RprNzeHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#                             **Task**  \n",
        "\n",
        "Creating a Python-based backend service that integrates with Redis for storing and querying vector data. The service will simulate the functionality of an AI-powered documentation assistant, allowing documents to be uploaded, vectorized, stored, and queried for similarity search. This project will assess your proficiency in Python, Redis, and AI/ML integration.\n",
        "\n",
        "**Task Details:**\n",
        "\n",
        "1.\n",
        "Create a Python Backend Service\n",
        "\n",
        "o\n",
        "Develop a Python-based backend service using FastAPI (or Flask/Django) that provides the following endpoints:\n",
        "\n",
        "▪\n",
        "Upload Document Endpoint: Allows a user to upload documents and processes them to create vector embeddings.\n",
        "\n",
        "▪\n",
        "Search Endpoint: Accepts a user query and performs a similarity search in Redis, returning the most relevant documents along with similarity scores.\n",
        "\n",
        "\n",
        "2.\n",
        "Redis Vector Database Implementation\n",
        "\n",
        "o\n",
        "Set up and configure Redis with vector database capabilities (using modules like Redis Vector Search or RedisAI).\n",
        "\n",
        "o\n",
        "Use Redis as a store for the vector embeddings, ensuring data is properly indexed and optimized for similarity search.\n",
        "\n",
        "o\n",
        "Implement an indexing strategy to efficiently handle document vectors for quick retrieval.\n",
        "\n",
        "\n",
        "3.\n",
        "AI/ML Integration\n",
        "\n",
        "o\n",
        "Integrate a pre-trained model (e.g., OpenAI's GPT embeddings, Sentence Transformers) to process the text and generate vector embeddings for each document.\n",
        "\n",
        "o\n",
        "Implement the preprocessing logic required to prepare documents before vectorization.\n",
        "\n",
        "\n",
        "4.\n",
        "Search Functionality\n",
        "\n",
        "o\n",
        "Implement a similarity search endpoint that:\n",
        "▪\n",
        "\n",
        "Takes a text query, vectorizes it using the chosen embedding model, and retrieves the most similar documents stored in Redis.\n",
        "\n",
        "▪\n",
        "Returns the top matching document(s) along with similarity scores in the response.\n",
        "\n",
        "5.\n",
        "Performance Considerations\n",
        "\n",
        "o\n",
        "Use Redis data structures to optimize memory usage and search operations for large-scale data.\n",
        "\n",
        "o\n",
        "Implement error handling, ensuring the system is robust and handles unexpected situations gracefully.\n",
        "\n",
        "o\n",
        "Demonstrate parallel processing or batch processing if necessary to improve performance during data ingestion.\n",
        "\n",
        "\n",
        "6.\n",
        "Documentation\n",
        "\n",
        "o\n",
        "Provide documentation on:\n",
        "\n",
        "▪\n",
        "How to set up and run the backend service with Redis.\n",
        "\n",
        "▪\n",
        "How to interact with the API endpoints.\n",
        "\n",
        "o\n",
        "Explain your choice of Redis modules and data structures, and any design decisions made.\n",
        "\n",
        "\n",
        "<!-- Evaluation Criteria: -->\n",
        "\n",
        "•\n",
        "Technical Skills: Proficiency in Python, FastAPI/Flask/Django, and Redis (including Redis Vector Search or RedisAI).\n",
        "\n",
        "•\n",
        "Problem-Solving: Ability to optimize vector storage and similarity search for large data sets using Redis.\n",
        "\n",
        "•\n",
        "Code Quality: Clean, modular, well-documented, and maintainable code with appropriate error handling.\n",
        "\n",
        "•\n",
        "Performance and Scalability: Efficient use of Redis for storage and retrieval, with considerations for scalability.\n",
        "\n",
        "•\n",
        "Creativity: Innovative solutions for optimizing data ingestion and retrieval.\n",
        "\n",
        "•\n",
        "Documentation and Communication: Clear explanations of how to use the system and why specific choices were made."
      ],
      "metadata": {
        "id": "FRvw2EIazeQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn sentence-transformers redis pyngrok nest-asyncio\n",
        "!apt-get install redis-server\n",
        "!redis-server --daemonize yes\n"
      ],
      "metadata": {
        "id": "QxdQzr4Lziiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import redis\n",
        "import numpy as np\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "pZ3kbYNbzeoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing Redis connection\n",
        "redis_host = \"localhost\"\n",
        "redis_port = 6379\n",
        "redis_client = redis.StrictRedis(host=redis_host, port=redis_port, decode_responses=False)"
      ],
      "metadata": {
        "id": "I6xs8LlI2RLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading SentenceTransformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "9ibvaHb42UI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FastAPI application\n",
        "app = FastAPI()"
      ],
      "metadata": {
        "id": "FiwxsUtd2ULr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pydantic model for document upload\n",
        "class Document(BaseModel):\n",
        "    document_id: str\n",
        "    content: str"
      ],
      "metadata": {
        "id": "yQRqISx12UPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Endpoint to uploading documents\n",
        "@app.post(\"/upload\")\n",
        "def upload_document(doc: Document):\n",
        "    try:\n",
        "        # Generating vector embedding\n",
        "        embedding = model.encode(doc.content).tolist()\n",
        "\n",
        "        # Storing embedding in Redis\n",
        "        key = f\"vector:{doc.document_id}\"\n",
        "        redis_client.hset(key, mapping={\n",
        "            \"embedding\": np.array(embedding).tobytes(),\n",
        "            \"content\": doc.content\n",
        "        })\n",
        "        return {\"message\": \"Document uploaded successfully\", \"document_id\": doc.document_id}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ],
      "metadata": {
        "id": "fO3TAlna2e_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Endpoint for similarity search\n",
        "@app.get(\"/search\")\n",
        "def search_documents(query: str, top_k: int = 3):\n",
        "    try:\n",
        "        # Vectorizing query\n",
        "        query_vector = model.encode(query)\n",
        "\n",
        "        # Performing similarity search\n",
        "        keys = redis_client.keys(\"vector:*\")\n",
        "        results = []\n",
        "\n",
        "        for key in keys:\n",
        "            stored_embedding = np.frombuffer(redis_client.hget(key, \"embedding\"), dtype=np.float32)\n",
        "            similarity = np.dot(query_vector, stored_embedding) / (\n",
        "                np.linalg.norm(query_vector) * np.linalg.norm(stored_embedding)\n",
        "            )\n",
        "            results.append({\n",
        "                \"document_id\": key.decode('utf-8').split(\":\")[1],\n",
        "                \"similarity_score\": similarity,\n",
        "                \"content\": redis_client.hget(key, \"content\").decode('utf-8')\n",
        "            })\n",
        "\n",
        "        # Sorting results by similarity score\n",
        "        sorted_results = sorted(results, key=lambda x: x['similarity_score'], reverse=True)[:top_k]\n",
        "\n",
        "        return {\"results\": sorted_results}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))"
      ],
      "metadata": {
        "id": "yQKs_wxG2fCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
      ],
      "metadata": {
        "id": "oy_KwadOzerH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWoJmu1j0AH6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}